{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import image_dataset_from_directory\n",
    "from tensorflow import clip_by_value\n",
    "from tensorflow import data as tf_data\n",
    "from tensorflow import image as tf_image\n",
    "from tensorflow import random as tf_random\n",
    "import keras_cv\n",
    "from keras import layers, models\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.regularizers import l1_l2\n",
    "input_shape = (32, 32, 3)\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Input, Rescaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 90000 files belonging to 10 classes.\n",
      "Using 72000 files for training.\n",
      "Found 90000 files belonging to 10 classes.\n",
      "Using 18000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds = image_dataset_from_directory(\n",
    "    '../data/cinic-10_image_classification_challenge-dataset/train/',\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed = 420,\n",
    "    image_size=(32,32),\n",
    "    batch_size=32,\n",
    "    label_mode = 'categorical')\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    '../data/cinic-10_image_classification_challenge-dataset/train/',\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed = 420,\n",
    "    image_size=(32,32),\n",
    "    batch_size=32,\n",
    "    label_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_and_preprocess_image(image_path, label):\n",
    "#     # Load image\n",
    "#     image = tf.io.read_file(image_path)\n",
    "#     # Decode PNG image to tensor\n",
    "#     image = tf.image.decode_png(image, channels=3)  # Adjust channels according to your images\n",
    "#     # Normalize pixel values to range [0, 1]\n",
    "#     image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "#     return image, label\n",
    "\n",
    "\n",
    "# def preprocess_data():\n",
    "\n",
    "#     class_names = os.listdir(data_dir)\n",
    "\n",
    "#     image_paths = []\n",
    "#     labels = []\n",
    "#     for class_name in class_names:\n",
    "#         class_dir = os.path.join(data_dir, class_name)\n",
    "#         for image_name in os.listdir(class_dir):\n",
    "#             image_path = os.path.join(class_dir, image_name)\n",
    "#             image_paths.append(image_path)\n",
    "#             labels.append(class_names.index(class_name))\n",
    "\n",
    "#     # Create TensorFlow Dataset from the loaded data\n",
    "#     dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "#     dataset = dataset.map(load_and_preprocess_image)\n",
    "\n",
    "#     dataset = dataset.shuffle(buffer_size=10000)\n",
    "\n",
    "# # Split the dataset into train, validation, and test sets\n",
    "#     train_size = int(0.8 * len(dataset))\n",
    "#     test_size = int(0.2 * len(dataset))\n",
    "\n",
    "#     train_dataset = dataset.take(train_size)\n",
    "#     test_dataset = dataset.skip(train_size).take(test_size)\n",
    "#     train_dataset = train_dataset.shuffle(buffer_size=len(image_paths)).batch(32)\n",
    "#     test_dataset = test_dataset.shuffle(buffer_size=len(image_paths)).batch(32)\n",
    "#     return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre-made dataset from cifar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = preprocess_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(input_shape, l1=0.01, l2=0.01, dropout_rate=0.2):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Convolutional layers\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, kernel_regularizer=l1_l2(l1, l2))) # output shape is 30x30x32\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2))) # output shape is 15x15x32\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l1_l2(l1, l2))) # output shape is 13x13x64\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2))) # output shape is 6x6x64\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "\n",
    "    # model.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l1_l2(l1, l2)))\n",
    "    # model.add(layers.BatchNormalization())\n",
    "    # model.add(layers.MaxPooling2D((2,2)))\n",
    "    # model.add(layers.BatchNormalization())\n",
    "    # model.add(layers.Dropout(dropout_rate))\n",
    "    # Dense layers\n",
    "    model.add(layers.Flatten()) # 1024\n",
    "    model.add(layers.Dense(256, activation='relu', kernel_regularizer=l1_l2(l1, l2)))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    model.add(layers.Dense(10, activation='softmax', kernel_regularizer=l1_l2(l1, l2)))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_17          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4608</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m1,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_17          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4608\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m1,179,904\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m2,570\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,658</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,658\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,258,890</span> (4.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,258,890\u001b[0m (4.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = cnn(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### searching for optimal dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropout = 0.0\n",
      "Epoch 1/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 50ms/step - accuracy: 0.1029 - loss: 1013.8644 - val_accuracy: 0.1024 - val_loss: 154.9450\n",
      "Epoch 2/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 49ms/step - accuracy: 0.0983 - loss: 154.5016 - val_accuracy: 0.1024 - val_loss: 154.2294\n",
      "Epoch 3/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 49ms/step - accuracy: 0.0990 - loss: 154.2608 - val_accuracy: 0.1024 - val_loss: 155.0517\n",
      "Epoch 4/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 50ms/step - accuracy: 0.0977 - loss: 154.0106 - val_accuracy: 0.1024 - val_loss: 153.5535\n",
      "Epoch 5/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 50ms/step - accuracy: 0.0977 - loss: 153.7660 - val_accuracy: 0.1024 - val_loss: 154.5997\n",
      "dropout = 0.05555555555555555\n",
      "Epoch 1/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 46ms/step - accuracy: 0.1019 - loss: 1015.7307 - val_accuracy: 0.1024 - val_loss: 153.9177\n",
      "Epoch 2/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 44ms/step - accuracy: 0.0994 - loss: 153.7995 - val_accuracy: 0.1024 - val_loss: 153.5822\n",
      "Epoch 3/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 46ms/step - accuracy: 0.0981 - loss: 153.5611 - val_accuracy: 0.1024 - val_loss: 153.9943\n",
      "Epoch 4/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 44ms/step - accuracy: 0.0983 - loss: 153.3258 - val_accuracy: 0.1024 - val_loss: 152.9283\n",
      "Epoch 5/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 45ms/step - accuracy: 0.0972 - loss: 153.0794 - val_accuracy: 0.1024 - val_loss: 153.8617\n",
      "dropout = 0.1111111111111111\n",
      "Epoch 1/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 45ms/step - accuracy: 0.1028 - loss: 1014.4180 - val_accuracy: 0.1024 - val_loss: 154.6282\n",
      "Epoch 2/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 45ms/step - accuracy: 0.0978 - loss: 154.3712 - val_accuracy: 0.1024 - val_loss: 153.9676\n",
      "Epoch 3/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 45ms/step - accuracy: 0.0991 - loss: 154.1270 - val_accuracy: 0.1024 - val_loss: 154.8396\n",
      "Epoch 4/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 45ms/step - accuracy: 0.0981 - loss: 153.8896 - val_accuracy: 0.1024 - val_loss: 153.3956\n",
      "Epoch 5/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 45ms/step - accuracy: 0.0981 - loss: 153.6578 - val_accuracy: 0.1024 - val_loss: 154.4591\n",
      "dropout = 0.16666666666666666\n",
      "Epoch 1/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 46ms/step - accuracy: 0.1001 - loss: 1014.5715 - val_accuracy: 0.1024 - val_loss: 153.9153\n",
      "Epoch 2/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 45ms/step - accuracy: 0.0977 - loss: 153.6588 - val_accuracy: 0.1024 - val_loss: 153.2919\n",
      "Epoch 3/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 45ms/step - accuracy: 0.0982 - loss: 153.4206 - val_accuracy: 0.1024 - val_loss: 154.0958\n",
      "Epoch 4/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 44ms/step - accuracy: 0.0982 - loss: 153.1953 - val_accuracy: 0.1024 - val_loss: 152.7450\n",
      "Epoch 5/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 44ms/step - accuracy: 0.0978 - loss: 152.9449 - val_accuracy: 0.1024 - val_loss: 153.7838\n",
      "dropout = 0.2222222222222222\n",
      "Epoch 1/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 45ms/step - accuracy: 0.1002 - loss: 1013.1290 - val_accuracy: 0.1024 - val_loss: 153.4452\n",
      "Epoch 2/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 46ms/step - accuracy: 0.0979 - loss: 153.2370 - val_accuracy: 0.1024 - val_loss: 153.0229\n",
      "Epoch 3/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 45ms/step - accuracy: 0.0979 - loss: 153.0077 - val_accuracy: 0.1024 - val_loss: 153.6928\n",
      "Epoch 4/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 45ms/step - accuracy: 0.0989 - loss: 152.7798 - val_accuracy: 0.1024 - val_loss: 152.3996\n",
      "Epoch 5/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 45ms/step - accuracy: 0.0984 - loss: 152.5415 - val_accuracy: 0.1024 - val_loss: 153.2466\n",
      "dropout = 0.2777777777777778\n",
      "Epoch 1/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 45ms/step - accuracy: 0.1002 - loss: 1015.1610 - val_accuracy: 0.1024 - val_loss: 153.6222\n",
      "Epoch 2/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 45ms/step - accuracy: 0.0979 - loss: 153.4139 - val_accuracy: 0.1024 - val_loss: 153.0133\n",
      "Epoch 3/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 46ms/step - accuracy: 0.0980 - loss: 153.1675 - val_accuracy: 0.1024 - val_loss: 153.7501\n",
      "Epoch 4/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 45ms/step - accuracy: 0.0979 - loss: 152.9385 - val_accuracy: 0.1024 - val_loss: 152.3511\n",
      "Epoch 5/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 45ms/step - accuracy: 0.0990 - loss: 152.7180 - val_accuracy: 0.1024 - val_loss: 153.5691\n",
      "dropout = 0.3333333333333333\n",
      "Epoch 1/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 45ms/step - accuracy: 0.1023 - loss: 1014.0933 - val_accuracy: 0.1024 - val_loss: 153.0431\n",
      "Epoch 2/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 45ms/step - accuracy: 0.0981 - loss: 153.0238 - val_accuracy: 0.1024 - val_loss: 152.9263\n",
      "Epoch 3/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 45ms/step - accuracy: 0.0981 - loss: 152.7652 - val_accuracy: 0.1024 - val_loss: 153.2167\n",
      "Epoch 4/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 46ms/step - accuracy: 0.0973 - loss: 152.5332 - val_accuracy: 0.1024 - val_loss: 152.1663\n",
      "Epoch 5/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 46ms/step - accuracy: 0.0980 - loss: 152.3048 - val_accuracy: 0.1024 - val_loss: 152.8206\n",
      "dropout = 0.38888888888888884\n",
      "Epoch 1/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 50ms/step - accuracy: 0.1025 - loss: 1014.4590 - val_accuracy: 0.1024 - val_loss: 152.7228\n",
      "Epoch 2/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 46ms/step - accuracy: 0.0986 - loss: 152.5062 - val_accuracy: 0.1024 - val_loss: 152.3371\n",
      "Epoch 3/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 45ms/step - accuracy: 0.0979 - loss: 152.2716 - val_accuracy: 0.1024 - val_loss: 152.8159\n",
      "Epoch 4/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 45ms/step - accuracy: 0.0967 - loss: 152.0540 - val_accuracy: 0.1024 - val_loss: 151.5905\n",
      "Epoch 5/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 46ms/step - accuracy: 0.0989 - loss: 151.8344 - val_accuracy: 0.1024 - val_loss: 152.2894\n",
      "dropout = 0.4444444444444444\n",
      "Epoch 1/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 45ms/step - accuracy: 0.1000 - loss: 1014.5972 - val_accuracy: 0.1024 - val_loss: 152.6638\n",
      "Epoch 2/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 45ms/step - accuracy: 0.0980 - loss: 152.4252 - val_accuracy: 0.1024 - val_loss: 152.1822\n",
      "Epoch 3/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 45ms/step - accuracy: 0.0975 - loss: 152.1909 - val_accuracy: 0.1024 - val_loss: 152.7330\n",
      "Epoch 4/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 45ms/step - accuracy: 0.0984 - loss: 151.9642 - val_accuracy: 0.1024 - val_loss: 151.7699\n",
      "Epoch 5/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 45ms/step - accuracy: 0.0966 - loss: 151.7409 - val_accuracy: 0.1024 - val_loss: 152.1244\n",
      "dropout = 0.5\n",
      "Epoch 1/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 45ms/step - accuracy: 0.0989 - loss: 1013.3677 - val_accuracy: 0.1024 - val_loss: 151.9432\n",
      "Epoch 2/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 45ms/step - accuracy: 0.0988 - loss: 151.9418 - val_accuracy: 0.1024 - val_loss: 151.7739\n",
      "Epoch 3/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 45ms/step - accuracy: 0.0986 - loss: 151.6995 - val_accuracy: 0.1024 - val_loss: 152.1191\n",
      "Epoch 4/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 45ms/step - accuracy: 0.0985 - loss: 151.4675 - val_accuracy: 0.1024 - val_loss: 151.1330\n",
      "Epoch 5/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 49ms/step - accuracy: 0.0970 - loss: 151.2377 - val_accuracy: 0.1024 - val_loss: 151.6103\n"
     ]
    }
   ],
   "source": [
    "histories = {}\n",
    "for dropout_rate in np.linspace(0, 1/2, 10):\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)    \n",
    "    model = cnn(input_shape, True, dropout_rate=dropout_rate)\n",
    "    model.compile(optimizer=optimizer,\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "    print(f'dropout = {dropout_rate}')\n",
    "    history = model.fit(train_ds, validation_data = val_ds, epochs = 5)    \n",
    "    histories[dropout_rate] = {'history': history.history}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for dropout in histories:\n",
    "    plt.scatter(dropout, histories[dropout]['history']['val_accuracy'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1 = 0.0, l2 = 0.0\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 32s 11ms/step - loss: 1.7577 - accuracy: 0.3706\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 33s 12ms/step - loss: 1.4970 - accuracy: 0.4550\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 31s 11ms/step - loss: 1.4155 - accuracy: 0.4888\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 31s 11ms/step - loss: 1.3661 - accuracy: 0.5063\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 34s 12ms/step - loss: 1.3292 - accuracy: 0.5217\n",
      "563/563 [==============================] - 11s 5ms/step - loss: 3.8904 - accuracy: 0.2519\n",
      "l1 = 0.0, l2 = 0.1111111111111111\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 55s 18ms/step - loss: 3.3628 - accuracy: 0.3546\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 66s 25ms/step - loss: 1.9381 - accuracy: 0.3718\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 64s 22ms/step - loss: 1.9091 - accuracy: 0.3729\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 88s 31ms/step - loss: 1.8902 - accuracy: 0.3790\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 84s 31ms/step - loss: 1.8766 - accuracy: 0.3787\n",
      "563/563 [==============================] - 23s 10ms/step - loss: 4.8923 - accuracy: 0.1055\n",
      "l1 = 0.0, l2 = 0.2222222222222222\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 74s 25ms/step - loss: 3.8010 - accuracy: 0.3336\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 58s 21ms/step - loss: 1.9664 - accuracy: 0.3451\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 64s 24ms/step - loss: 1.9329 - accuracy: 0.3511\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 67s 24ms/step - loss: 1.9170 - accuracy: 0.3515\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 67s 24ms/step - loss: 1.9116 - accuracy: 0.3535\n",
      "563/563 [==============================] - 18s 8ms/step - loss: 5.1962 - accuracy: 0.0191\n",
      "l1 = 0.0, l2 = 0.3333333333333333\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 95s 29ms/step - loss: 3.9152 - accuracy: 0.3176\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 61s 22ms/step - loss: 2.0048 - accuracy: 0.3285\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 62s 20ms/step - loss: 1.9661 - accuracy: 0.3378\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 53s 19ms/step - loss: 1.9510 - accuracy: 0.3381\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 51s 18ms/step - loss: 1.9410 - accuracy: 0.3378\n",
      "563/563 [==============================] - 14s 6ms/step - loss: 4.9934 - accuracy: 0.0505\n",
      "l1 = 0.0, l2 = 0.4444444444444444\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 53s 19ms/step - loss: 4.3455 - accuracy: 0.2863\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 56s 21ms/step - loss: 2.0265 - accuracy: 0.2982\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 52s 19ms/step - loss: 1.9834 - accuracy: 0.3126\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 53s 19ms/step - loss: 1.9693 - accuracy: 0.3212\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 56s 21ms/step - loss: 1.9548 - accuracy: 0.3247\n",
      "563/563 [==============================] - 19s 7ms/step - loss: 4.9541 - accuracy: 0.0367\n",
      "l1 = 0.0, l2 = 0.5555555555555556\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 58s 20ms/step - loss: 4.6314 - accuracy: 0.2831\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 56s 20ms/step - loss: 2.0395 - accuracy: 0.2910\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 51s 18ms/step - loss: 1.9957 - accuracy: 0.2953\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 51s 18ms/step - loss: 1.9742 - accuracy: 0.3012\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 51s 18ms/step - loss: 1.9633 - accuracy: 0.3047\n",
      "563/563 [==============================] - 14s 6ms/step - loss: 4.6947 - accuracy: 0.0577\n",
      "l1 = 0.0, l2 = 0.6666666666666666\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 53s 18ms/step - loss: 4.8821 - accuracy: 0.2728\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 54s 19ms/step - loss: 2.0631 - accuracy: 0.2798\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 61s 23ms/step - loss: 2.0056 - accuracy: 0.2879\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 63s 23ms/step - loss: 1.9827 - accuracy: 0.2882\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 59s 22ms/step - loss: 1.9804 - accuracy: 0.2869\n",
      "563/563 [==============================] - 16s 7ms/step - loss: 4.5343 - accuracy: 0.0117\n",
      "l1 = 0.0, l2 = 0.7777777777777777\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 62s 21ms/step - loss: 5.1038 - accuracy: 0.2737\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 58s 21ms/step - loss: 2.0774 - accuracy: 0.2838\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 71s 26ms/step - loss: 2.0258 - accuracy: 0.2897\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 53s 20ms/step - loss: 2.0019 - accuracy: 0.2955\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 59s 21ms/step - loss: 1.9870 - accuracy: 0.2982\n",
      "563/563 [==============================] - 18s 9ms/step - loss: 4.7545 - accuracy: 0.0132\n",
      "l1 = 0.0, l2 = 0.8888888888888888\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 63s 22ms/step - loss: 5.4164 - accuracy: 0.2278\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 68s 24ms/step - loss: 2.0914 - accuracy: 0.2228\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 55s 20ms/step - loss: 2.0802 - accuracy: 0.2618\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 73s 27ms/step - loss: 2.0140 - accuracy: 0.2852\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 81s 30ms/step - loss: 1.9961 - accuracy: 0.2856\n",
      "563/563 [==============================] - 21s 10ms/step - loss: 5.6217 - accuracy: 0.0177\n",
      "l1 = 0.0, l2 = 1.0\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 67s 22ms/step - loss: 5.8090 - accuracy: 0.2301\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 58s 21ms/step - loss: 2.1025 - accuracy: 0.2209\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 62s 24ms/step - loss: 2.0956 - accuracy: 0.2216\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 78s 28ms/step - loss: 2.0683 - accuracy: 0.2260\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 79s 29ms/step - loss: 2.0439 - accuracy: 0.2246\n",
      "563/563 [==============================] - 17s 7ms/step - loss: 5.9817 - accuracy: 3.8889e-04\n",
      "l1 = 0.1111111111111111, l2 = 0.0\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 61s 22ms/step - loss: 11.7467 - accuracy: 0.1266\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 55s 20ms/step - loss: 3.8096 - accuracy: 0.1258\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 53s 20ms/step - loss: 3.8031 - accuracy: 0.1243\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 58s 22ms/step - loss: 3.8030 - accuracy: 0.1229\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 71s 26ms/step - loss: 3.8018 - accuracy: 0.1232\n",
      "563/563 [==============================] - 18s 8ms/step - loss: 6.3755 - accuracy: 3.8889e-04\n",
      "l1 = 0.1111111111111111, l2 = 0.1111111111111111\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 69s 24ms/step - loss: 11.8086 - accuracy: 0.1251\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 61s 22ms/step - loss: 3.8362 - accuracy: 0.1227\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 62s 23ms/step - loss: 3.8335 - accuracy: 0.1238\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 64s 24ms/step - loss: 3.8311 - accuracy: 0.1250\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 75s 28ms/step - loss: 3.8321 - accuracy: 0.1242\n",
      "563/563 [==============================] - 20s 12ms/step - loss: 6.3312 - accuracy: 0.0086\n",
      "l1 = 0.1111111111111111, l2 = 0.2222222222222222\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 92s 33ms/step - loss: 12.2286 - accuracy: 0.1244\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 50s 17ms/step - loss: 3.8378 - accuracy: 0.1246\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 51s 18ms/step - loss: 3.8345 - accuracy: 0.1237\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 71s 26ms/step - loss: 3.8326 - accuracy: 0.1233\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 65s 25ms/step - loss: 3.8315 - accuracy: 0.1244\n",
      "563/563 [==============================] - 19s 10ms/step - loss: 6.3638 - accuracy: 5.0000e-04\n",
      "l1 = 0.1111111111111111, l2 = 0.3333333333333333\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 88s 32ms/step - loss: 12.3631 - accuracy: 0.1254\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 63s 22ms/step - loss: 3.8465 - accuracy: 0.1235\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 63s 23ms/step - loss: 3.8425 - accuracy: 0.1236\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 58s 21ms/step - loss: 3.8412 - accuracy: 0.1237\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 89s 35ms/step - loss: 3.8399 - accuracy: 0.1248\n",
      "563/563 [==============================] - 17s 8ms/step - loss: 6.3918 - accuracy: 5.0000e-04\n",
      "l1 = 0.1111111111111111, l2 = 0.4444444444444444\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 97s 36ms/step - loss: 12.6374 - accuracy: 0.1254\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 92s 36ms/step - loss: 3.8593 - accuracy: 0.1236\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 82s 31ms/step - loss: 3.8557 - accuracy: 0.1228\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 83s 31ms/step - loss: 3.8529 - accuracy: 0.1241\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 86s 33ms/step - loss: 3.8530 - accuracy: 0.1215\n",
      "563/563 [==============================] - 20s 11ms/step - loss: 6.4289 - accuracy: 8.3333e-04\n",
      "l1 = 0.1111111111111111, l2 = 0.5555555555555556\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 91s 34ms/step - loss: 12.9626 - accuracy: 0.1236\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 72s 27ms/step - loss: 3.8763 - accuracy: 0.1247\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 85s 33ms/step - loss: 3.8722 - accuracy: 0.1247\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 86s 33ms/step - loss: 3.8705 - accuracy: 0.1225\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 79s 30ms/step - loss: 3.8707 - accuracy: 0.1248\n",
      "563/563 [==============================] - 20s 11ms/step - loss: 6.3902 - accuracy: 0.0019\n",
      "l1 = 0.1111111111111111, l2 = 0.6666666666666666\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 78s 28ms/step - loss: 13.3745 - accuracy: 0.1233\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 82s 31ms/step - loss: 3.8836 - accuracy: 0.1247\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 82s 30ms/step - loss: 3.8796 - accuracy: 0.1230\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 85s 32ms/step - loss: 3.8781 - accuracy: 0.1245\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 80s 29ms/step - loss: 3.8769 - accuracy: 0.1225\n",
      "563/563 [==============================] - 18s 8ms/step - loss: 6.4391 - accuracy: 0.0012\n",
      "l1 = 0.1111111111111111, l2 = 0.7777777777777777\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 67s 24ms/step - loss: 13.5895 - accuracy: 0.1252\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 80s 30ms/step - loss: 3.8717 - accuracy: 0.1225\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 76s 28ms/step - loss: 3.8695 - accuracy: 0.1236\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 72s 26ms/step - loss: 3.8669 - accuracy: 0.1240\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 57s 21ms/step - loss: 3.8665 - accuracy: 0.1242\n",
      "563/563 [==============================] - 13s 6ms/step - loss: 6.4766 - accuracy: 0.0033\n",
      "l1 = 0.1111111111111111, l2 = 0.8888888888888888\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 62s 22ms/step - loss: 13.8247 - accuracy: 0.1246\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 55s 20ms/step - loss: 3.8499 - accuracy: 0.1236\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 56s 21ms/step - loss: 3.8463 - accuracy: 0.1246\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 56s 20ms/step - loss: 3.8463 - accuracy: 0.1231\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 54s 20ms/step - loss: 3.8447 - accuracy: 0.1239\n",
      "563/563 [==============================] - 14s 7ms/step - loss: 6.3664 - accuracy: 4.4444e-04\n",
      "l1 = 0.1111111111111111, l2 = 1.0\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 56s 20ms/step - loss: 14.0804 - accuracy: 0.1244\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 54s 19ms/step - loss: 3.8523 - accuracy: 0.1236\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 54s 20ms/step - loss: 3.8502 - accuracy: 0.1230\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 57s 21ms/step - loss: 3.8478 - accuracy: 0.1225\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 50s 18ms/step - loss: 3.8483 - accuracy: 0.1229\n",
      "563/563 [==============================] - 13s 6ms/step - loss: 6.3561 - accuracy: 5.5556e-04\n",
      "l1 = 0.2222222222222222, l2 = 0.0\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 52s 18ms/step - loss: 19.3425 - accuracy: 0.1254\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 50s 18ms/step - loss: 5.5191 - accuracy: 0.1232\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 51s 18ms/step - loss: 5.5131 - accuracy: 0.1244\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 51s 19ms/step - loss: 5.5112 - accuracy: 0.1235\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 57s 21ms/step - loss: 5.5104 - accuracy: 0.1230\n",
      "563/563 [==============================] - 15s 6ms/step - loss: 8.0643 - accuracy: 7.2222e-04\n",
      "l1 = 0.2222222222222222, l2 = 0.1111111111111111\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 52s 18ms/step - loss: 19.7391 - accuracy: 0.1219\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 51s 19ms/step - loss: 5.4277 - accuracy: 0.1235\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 51s 18ms/step - loss: 5.5149 - accuracy: 0.1233\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 50s 18ms/step - loss: 5.5187 - accuracy: 0.1230\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 50s 18ms/step - loss: 5.5173 - accuracy: 0.1248\n",
      "563/563 [==============================] - 13s 6ms/step - loss: 8.0689 - accuracy: 0.0035\n",
      "l1 = 0.2222222222222222, l2 = 0.2222222222222222\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 50s 17ms/step - loss: 20.0471 - accuracy: 0.1234\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 48s 17ms/step - loss: 5.5342 - accuracy: 0.1236\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 48s 17ms/step - loss: 5.5321 - accuracy: 0.1243\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 48s 17ms/step - loss: 5.5305 - accuracy: 0.1229\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 48s 17ms/step - loss: 5.5302 - accuracy: 0.1216\n",
      "563/563 [==============================] - 13s 6ms/step - loss: 8.0718 - accuracy: 6.1111e-04\n",
      "l1 = 0.2222222222222222, l2 = 0.3333333333333333\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 50s 17ms/step - loss: 20.1981 - accuracy: 0.1257\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 48s 17ms/step - loss: 5.5364 - accuracy: 0.1231\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 47s 17ms/step - loss: 5.5332 - accuracy: 0.1236\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 47s 17ms/step - loss: 5.5321 - accuracy: 0.1227\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 48s 17ms/step - loss: 5.5307 - accuracy: 0.1233\n",
      "563/563 [==============================] - 13s 6ms/step - loss: 8.0593 - accuracy: 0.0087\n",
      "l1 = 0.2222222222222222, l2 = 0.4444444444444444\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 50s 17ms/step - loss: 20.5550 - accuracy: 0.1252\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 47s 17ms/step - loss: 5.5485 - accuracy: 0.1239\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 48s 17ms/step - loss: 5.5447 - accuracy: 0.1247\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 47s 17ms/step - loss: 5.5434 - accuracy: 0.1238\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 48s 17ms/step - loss: 5.5417 - accuracy: 0.1238\n",
      "563/563 [==============================] - 13s 6ms/step - loss: 8.0672 - accuracy: 2.2222e-04\n",
      "l1 = 0.2222222222222222, l2 = 0.5555555555555556\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 51s 18ms/step - loss: 20.8128 - accuracy: 0.1241\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 49s 18ms/step - loss: 5.5765 - accuracy: 0.1237\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 48s 17ms/step - loss: 5.5719 - accuracy: 0.1232\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 48s 17ms/step - loss: 5.5701 - accuracy: 0.1230\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 48s 17ms/step - loss: 5.5694 - accuracy: 0.1242\n",
      "563/563 [==============================] - 13s 5ms/step - loss: 8.0991 - accuracy: 3.3333e-04\n",
      "l1 = 0.2222222222222222, l2 = 0.6666666666666666\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 50s 17ms/step - loss: 21.3098 - accuracy: 0.1252\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 47s 17ms/step - loss: 5.5701 - accuracy: 0.1240\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 52s 19ms/step - loss: 5.5655 - accuracy: 0.1235\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 52s 19ms/step - loss: 5.5649 - accuracy: 0.1232\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 51s 19ms/step - loss: 5.5638 - accuracy: 0.1252\n",
      "563/563 [==============================] - 17s 7ms/step - loss: 8.1058 - accuracy: 0.0011\n",
      "l1 = 0.2222222222222222, l2 = 0.7777777777777777\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 61s 22ms/step - loss: 21.5519 - accuracy: 0.1237\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 60s 21ms/step - loss: 5.5894 - accuracy: 0.1240\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 61s 23ms/step - loss: 5.5857 - accuracy: 0.1247\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 71s 26ms/step - loss: 5.5833 - accuracy: 0.1240\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 68s 25ms/step - loss: 5.5827 - accuracy: 0.1226\n",
      "563/563 [==============================] - 17s 7ms/step - loss: 8.1310 - accuracy: 1.1111e-04\n",
      "l1 = 0.2222222222222222, l2 = 0.8888888888888888\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 71s 25ms/step - loss: 21.9072 - accuracy: 0.1240\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 67s 25ms/step - loss: 5.6146 - accuracy: 0.1236\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 81s 31ms/step - loss: 5.6097 - accuracy: 0.1238\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 77s 28ms/step - loss: 5.6092 - accuracy: 0.1212\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 82s 30ms/step - loss: 5.6081 - accuracy: 0.1242\n",
      "563/563 [==============================] - 20s 10ms/step - loss: 8.1380 - accuracy: 5.5556e-04\n",
      "l1 = 0.2222222222222222, l2 = 1.0\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 83s 30ms/step - loss: 22.0542 - accuracy: 0.1256\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 69s 25ms/step - loss: 5.5936 - accuracy: 0.1245\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 70s 26ms/step - loss: 5.5890 - accuracy: 0.1230\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 70s 26ms/step - loss: 5.5881 - accuracy: 0.1223\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 68s 25ms/step - loss: 5.5879 - accuracy: 0.1244\n",
      "563/563 [==============================] - 15s 6ms/step - loss: 8.1186 - accuracy: 4.4444e-04\n",
      "l1 = 0.3333333333333333, l2 = 0.0\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 64s 22ms/step - loss: 27.1982 - accuracy: 0.1245\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 66s 25ms/step - loss: 7.2096 - accuracy: 0.1241\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 52s 18ms/step - loss: 7.2028 - accuracy: 0.1246\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 75s 27ms/step - loss: 7.2021 - accuracy: 0.1222\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 62s 21ms/step - loss: 7.2013 - accuracy: 0.1223\n",
      "563/563 [==============================] - 15s 6ms/step - loss: 9.7478 - accuracy: 5.5556e-04\n",
      "l1 = 0.3333333333333333, l2 = 0.1111111111111111\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 61s 21ms/step - loss: 27.6042 - accuracy: 0.1250\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 59s 22ms/step - loss: 7.0000 - accuracy: 0.1226\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 59s 21ms/step - loss: 7.0704 - accuracy: 0.1241\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 60s 22ms/step - loss: 7.1884 - accuracy: 0.1233\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 71s 26ms/step - loss: 7.1937 - accuracy: 0.1241\n",
      "563/563 [==============================] - 18s 9ms/step - loss: 9.7511 - accuracy: 0.0013\n",
      "l1 = 0.3333333333333333, l2 = 0.2222222222222222\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 86s 32ms/step - loss: 28.0111 - accuracy: 0.1243\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 81s 31ms/step - loss: 7.1517 - accuracy: 0.1219\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 82s 31ms/step - loss: 7.2147 - accuracy: 0.1242\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 82s 31ms/step - loss: 7.2149 - accuracy: 0.1229\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 82s 31ms/step - loss: 7.2146 - accuracy: 0.1235\n",
      "563/563 [==============================] - 20s 9ms/step - loss: 9.7703 - accuracy: 4.4444e-04\n",
      "l1 = 0.3333333333333333, l2 = 0.3333333333333333\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 79s 28ms/step - loss: 28.1280 - accuracy: 0.1234\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 82s 30ms/step - loss: 7.2223 - accuracy: 0.1240\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 79s 29ms/step - loss: 7.2211 - accuracy: 0.1222\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 82s 30ms/step - loss: 7.2193 - accuracy: 0.1240\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 78s 29ms/step - loss: 7.2181 - accuracy: 0.1234\n",
      "563/563 [==============================] - 19s 10ms/step - loss: 9.7890 - accuracy: 0.0012\n",
      "l1 = 0.3333333333333333, l2 = 0.4444444444444444\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 89s 31ms/step - loss: 28.4508 - accuracy: 0.1233\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 88s 33ms/step - loss: 7.2524 - accuracy: 0.1236\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 91s 33ms/step - loss: 7.2440 - accuracy: 0.1228\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 88s 33ms/step - loss: 7.2432 - accuracy: 0.1256\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 92s 34ms/step - loss: 7.2419 - accuracy: 0.1245\n",
      "563/563 [==============================] - 25s 11ms/step - loss: 9.8082 - accuracy: 4.4444e-04\n",
      "l1 = 0.3333333333333333, l2 = 0.5555555555555556\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 97s 34ms/step - loss: 28.8560 - accuracy: 0.1218\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 91s 33ms/step - loss: 7.2395 - accuracy: 0.1243\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 89s 33ms/step - loss: 7.2372 - accuracy: 0.1238\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 91s 33ms/step - loss: 7.2350 - accuracy: 0.1251\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 88s 33ms/step - loss: 7.2356 - accuracy: 0.1211\n",
      "563/563 [==============================] - 22s 11ms/step - loss: 9.7698 - accuracy: 0.0011\n",
      "l1 = 0.3333333333333333, l2 = 0.6666666666666666\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 94s 33ms/step - loss: 29.1028 - accuracy: 0.1241\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 90s 33ms/step - loss: 7.2572 - accuracy: 0.1230\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 68s 24ms/step - loss: 7.2542 - accuracy: 0.1232\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 55s 19ms/step - loss: 7.2524 - accuracy: 0.1248\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 54s 19ms/step - loss: 7.2525 - accuracy: 0.1246\n",
      "563/563 [==============================] - 16s 6ms/step - loss: 9.7986 - accuracy: 2.7778e-04\n",
      "l1 = 0.3333333333333333, l2 = 0.7777777777777777\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 56s 19ms/step - loss: 29.6350 - accuracy: 0.1220\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 54s 19ms/step - loss: 7.2970 - accuracy: 0.1235\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 53s 19ms/step - loss: 7.2924 - accuracy: 0.1233\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 54s 19ms/step - loss: 7.2911 - accuracy: 0.1220\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 53s 18ms/step - loss: 7.2908 - accuracy: 0.1247\n",
      "563/563 [==============================] - 16s 6ms/step - loss: 9.8296 - accuracy: 0.0037\n",
      "l1 = 0.3333333333333333, l2 = 0.8888888888888888\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 58s 19ms/step - loss: 30.0066 - accuracy: 0.1240\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 55s 19ms/step - loss: 7.2938 - accuracy: 0.1224\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 55s 19ms/step - loss: 7.2898 - accuracy: 0.1250\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 55s 19ms/step - loss: 7.2883 - accuracy: 0.1230\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 54s 19ms/step - loss: 7.2872 - accuracy: 0.1255\n",
      "563/563 [==============================] - 17s 6ms/step - loss: 9.7930 - accuracy: 5.5556e-04\n",
      "l1 = 0.3333333333333333, l2 = 1.0\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 56s 19ms/step - loss: 30.2281 - accuracy: 0.1237\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 55s 19ms/step - loss: 7.3327 - accuracy: 0.1236\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 54s 19ms/step - loss: 7.3290 - accuracy: 0.1238\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 54s 19ms/step - loss: 7.3267 - accuracy: 0.1251\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 54s 19ms/step - loss: 7.3264 - accuracy: 0.1207\n",
      "563/563 [==============================] - 16s 6ms/step - loss: 9.9024 - accuracy: 6.6667e-04\n",
      "l1 = 0.4444444444444444, l2 = 0.0\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 56s 19ms/step - loss: 35.4045 - accuracy: 0.1234\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 54s 19ms/step - loss: 8.9076 - accuracy: 0.1238\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 55s 19ms/step - loss: 8.9012 - accuracy: 0.1221\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 55s 19ms/step - loss: 8.8986 - accuracy: 0.1233\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 53s 18ms/step - loss: 8.8970 - accuracy: 0.1226\n",
      "563/563 [==============================] - 17s 6ms/step - loss: 11.4081 - accuracy: 5.5556e-04\n",
      "l1 = 0.4444444444444444, l2 = 0.1111111111111111\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 56s 19ms/step - loss: 35.5252 - accuracy: 0.1243\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 54s 19ms/step - loss: 8.5842 - accuracy: 0.1225\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 55s 19ms/step - loss: 8.6213 - accuracy: 0.1246\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 54s 19ms/step - loss: 8.7108 - accuracy: 0.1237\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 54s 19ms/step - loss: 8.8492 - accuracy: 0.1234\n",
      "563/563 [==============================] - 16s 6ms/step - loss: 11.3987 - accuracy: 3.8889e-04\n",
      "l1 = 0.4444444444444444, l2 = 0.2222222222222222\n",
      "Epoch 1/5\n",
      "2250/2250 [==============================] - 56s 19ms/step - loss: 35.8312 - accuracy: 0.1246\n",
      "Epoch 2/5\n",
      "2250/2250 [==============================] - 54s 19ms/step - loss: 8.7264 - accuracy: 0.1251\n",
      "Epoch 3/5\n",
      "2250/2250 [==============================] - 54s 19ms/step - loss: 8.9004 - accuracy: 0.1255\n",
      "Epoch 4/5\n",
      "2250/2250 [==============================] - 62s 23ms/step - loss: 8.9082 - accuracy: 0.1256\n",
      "Epoch 5/5\n",
      "2250/2250 [==============================] - 38s 14ms/step - loss: 8.9081 - accuracy: 0.1229\n",
      "563/563 [==============================] - 11s 4ms/step - loss: 11.4507 - accuracy: 0.0030\n",
      "l1 = 0.4444444444444444, l2 = 0.3333333333333333\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m     11\u001b[0m         loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     12\u001b[0m         metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1 = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ml1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, l2 = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ml2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m    \n\u001b[0;32m     15\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_dataset)\n\u001b[0;32m     16\u001b[0m histories[(l1, l2)] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m'\u001b[39m: history\u001b[38;5;241m.\u001b[39mhistory,\n\u001b[0;32m     17\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: test_loss,\n\u001b[0;32m     18\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_acc\u001b[39m\u001b[38;5;124m'\u001b[39m: test_acc}\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1805\u001b[0m ):\n\u001b[0;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:905\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    901\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    902\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    904\u001b[0m     \u001b[38;5;66;03m# no_variable_creation function.\u001b[39;00m\n\u001b[1;32m--> 905\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    906\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    907\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    909\u001b[0m   bound_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\n\u001b[0;32m    910\u001b[0m       \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds\n\u001b[0;32m    911\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "l1_range = np.linspace(0, 1, 10)  # Example: 10 values between 0 and 1\n",
    "l2_range = np.linspace(0, 1, 10)  # Example: 10 values between 0 and 1\n",
    "\n",
    "# Generate candidate combinations using grid search\n",
    "search_space = [(l1, l2) for l1 in l1_range for l2 in l2_range]\n",
    "for l1, l2 in search_space:\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)    \n",
    "    model = cnn(input_shape, True, l1, l2)\n",
    "    model.compile(optimizer=optimizer,\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "    print(f'l1 = {l1}, l2 = {l2}')\n",
    "    history = model.fit(train_dataset, epochs = 5)    \n",
    "    test_loss, test_acc = model.evaluate(test_dataset)\n",
    "    histories[(l1, l2)] = {'history': history.history,\n",
    "                        'test_loss': test_loss,\n",
    "                        'test_acc': test_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for (l1, l2) in histories:\n",
    "    plt.scatter(l1, l2, s = histories[(l1, l2)]['test_acc']*400, c = histories[(l1, l2)]['test_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(dropout_rate = 0.2, batch_normalization = True):\n",
    "    model = models.Sequential()\n",
    "    model.add(Input((32,32,3)))\n",
    "    model.add(Rescaling(1./255))\n",
    "\n",
    "    model.add(Conv2D(64,(4,4),activation='relu'))\n",
    "    if batch_normalization:\n",
    "        model.add(layers.BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(128,(4,4),activation='relu'))\n",
    "    if batch_normalization:\n",
    "        model.add(layers.BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024,activation='relu'))\n",
    "    if batch_normalization:\n",
    "        model.add(layers.BatchNormalization())\n",
    "    model.add(Dense(1024,activation='relu'))\n",
    "    if batch_normalization:\n",
    "        model.add(layers.BatchNormalization())\n",
    "    model.add(Dense(10, activation = 'softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  base model, no dropout, no batch normalization after ReLu layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3200</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,277,824</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,250</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m3,136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m131,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3200\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m3,277,824\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m1,049,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │        \u001b[38;5;34m10,250\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,472,010</span> (17.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,472,010\u001b[0m (17.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,472,010</span> (17.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,472,010\u001b[0m (17.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = cnn(0, False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 62ms/step - accuracy: 0.3303 - loss: 1.7835 - val_accuracy: 0.4286 - val_loss: 1.5603\n",
      "Epoch 2/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 52ms/step - accuracy: 0.4737 - loss: 1.4318 - val_accuracy: 0.4984 - val_loss: 1.3697\n",
      "Epoch 3/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 51ms/step - accuracy: 0.5366 - loss: 1.2757 - val_accuracy: 0.5347 - val_loss: 1.3064\n",
      "Epoch 4/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 58ms/step - accuracy: 0.5821 - loss: 1.1375 - val_accuracy: 0.5075 - val_loss: 1.4665\n",
      "Epoch 5/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 54ms/step - accuracy: 0.6344 - loss: 0.9943 - val_accuracy: 0.5198 - val_loss: 1.5114\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, validation_data = val_ds, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 75ms/step - accuracy: 0.3543 - loss: 1.9189 - val_accuracy: 0.3597 - val_loss: 1.9804\n",
      "Epoch 2/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 81ms/step - accuracy: 0.4912 - loss: 1.4389 - val_accuracy: 0.4736 - val_loss: 1.5002\n",
      "Epoch 3/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 71ms/step - accuracy: 0.5588 - loss: 1.2591 - val_accuracy: 0.5508 - val_loss: 1.2861\n",
      "Epoch 4/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 69ms/step - accuracy: 0.6102 - loss: 1.1059 - val_accuracy: 0.5066 - val_loss: 1.5124\n",
      "Epoch 5/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 72ms/step - accuracy: 0.6549 - loss: 0.9702 - val_accuracy: 0.5347 - val_loss: 1.3931\n"
     ]
    }
   ],
   "source": [
    "histories = {}\n",
    "histories[(0, False)] = history\n",
    "model = cnn(0, True)\n",
    "history = model.fit(train_ds, validation_data = val_ds, epochs = 5)\n",
    "histories[(0, True)] = history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# base model without any augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 61ms/step - accuracy: 0.3328 - loss: 1.7821 - val_accuracy: 0.4490 - val_loss: 1.5015\n",
      "Epoch 2/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 61ms/step - accuracy: 0.4792 - loss: 1.4233 - val_accuracy: 0.4966 - val_loss: 1.3715\n",
      "Epoch 3/5\n",
      "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 67ms/step - accuracy: 0.5494 - loss: 1.2523 - val_accuracy: 0.4928 - val_loss: 1.4484\n",
      "Epoch 4/5\n",
      "\u001b[1m 385/2250\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:14\u001b[0m 72ms/step - accuracy: 0.5799 - loss: 1.1427"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_normalization \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m]:\n\u001b[0;32m      3\u001b[0m     model \u001b[38;5;241m=\u001b[39m cnn(dropout, batch_normalization)\n\u001b[1;32m----> 4\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     histories[(dropout, batch_normalization)] \u001b[38;5;241m=\u001b[39m history\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:325\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    324\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 325\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(\n\u001b[0;32m    327\u001b[0m         step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    328\u001b[0m     )\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for dropout in [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]:\n",
    "    for batch_normalization in [False, True]:\n",
    "        model = cnn(dropout, batch_normalization)\n",
    "        history = model.fit(train_ds, validation_data = val_ds, epochs = 5)\n",
    "        histories[(dropout, batch_normalization)] = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
