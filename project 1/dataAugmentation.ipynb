{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import image_dataset_from_directory\n",
    "from keras import layers, Model\n",
    "from PIL import Image\n",
    "from tensorflow import clip_by_value\n",
    "from tensorflow import data as tf_data\n",
    "from tensorflow import image as tf_image\n",
    "from tensorflow import random as tf_random\n",
    "import keras_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = image_dataset_from_directory(\n",
    "    '../data/cinic-10_image_classification_challenge-dataset/train/',\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed = 420,\n",
    "    image_size=(32,32),\n",
    "    batch_size=32,\n",
    "    # label_mode = 'categorical'\n",
    "    )\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    '../data/cinic-10_image_classification_challenge-dataset/train/',\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed = 420,\n",
    "    image_size=(32,32),\n",
    "    batch_size=32,\n",
    "    # label_mode = 'categorical'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(train_ds.class_names[labels[i]])\n",
    "    plt.axis(\"off\")\n",
    "plt.savefig('../media/cinic_10_examples.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# below code is for data augmentations, applied during training, on batches, as layers of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there's several layers:\n",
    "- RescaleLayer\n",
    "- RotateLayer\n",
    "- FlipLayer\n",
    "- DecolorizeLayer\n",
    "- GaussianNoiseLayer\n",
    "\n",
    "we use those at the beginning of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale to 0-1 range\n",
    "RescaleLayer = layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RotateLayer = layers.RandomRotation(0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FlipLayer = layers.RandomFlip(\"horizontal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decolorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecolorLayer = keras_cv.layers.Grayscale(output_channels=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GaussianNoise = layers.GaussianNoise(stddev = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_var_name(var):\n",
    "    for name, value in locals().items():\n",
    "        if value is var:\n",
    "            return name\n",
    "        \n",
    "image = images[0]\n",
    "image = RescaleLayer(image)\n",
    "fig, axes = plt.subplots(2,3, figsize=(12, 12))\n",
    "axes = axes.flatten()\n",
    "axes[0].imshow(image)\n",
    "axes[0].set_title('original image')\n",
    "axes[0].axis('off')\n",
    "for augmentationLayer, ax in zip([RotateLayer, FlipLayer, DecolorLayer, GaussianNoise], axes[1:]):\n",
    "    ax.imshow(augmentationLayer(image, training = True), cmap='grey' if augmentationLayer == DecolorLayer else None)\n",
    "    ax.set_title('Rescaled (visually does nothing)' if augmentationLayer == RescaleLayer else \n",
    "                 'Rotated' if augmentationLayer == RotateLayer else \n",
    "                 'Flipped' if augmentationLayer == FlipLayer else \n",
    "                 'Decolored' if augmentationLayer == DecolorLayer else \n",
    "                 'Noisy')\n",
    "    ax.axis('off')\n",
    "axes[-1].remove()\n",
    "plt.savefig('../media/standard_augmentations_example.jpg', dpi = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 32\n",
    "num_classes = 10\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "def to_dict(image, label):\n",
    "    # image = tf.image.resize(image, IMAGE_SIZE)\n",
    "    # image = tf.cast(image, tf.float32)\n",
    "    # label = tf.one_hot(label, num_classes)\n",
    "    return {\"images\": image, \"labels\": label}\n",
    "\n",
    "\n",
    "def prepare_dataset(dataset, split):\n",
    "    if split == \"train\":\n",
    "        return (\n",
    "            dataset.shuffle(10 * BATCH_SIZE)\n",
    "            .map(to_dict, num_parallel_calls=AUTOTUNE)\n",
    "            .batch(BATCH_SIZE)\n",
    "        )\n",
    "    if split == \"test\":\n",
    "        return dataset.map(to_dict, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_mix = keras_cv.layers.CutMix()\n",
    "\n",
    "def cutmix(samples):\n",
    "    samples = cut_mix(samples, training=True)\n",
    "    return samples\n",
    "# dict_train_ds = train_ds.map(to_dict, num_parallel_calls=AUTOTUNE)\n",
    "# dict_train_ds = dict_train_ds.map(cutmix, num_parallel_calls=AUTOTUNE)\n",
    "def dict_to_tuple(element):\n",
    "    return element['images'], element['labels']\n",
    "\n",
    "# cutmixed_ds = dict_train_ds.map(dict_to_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = image_dataset_from_directory(\n",
    "    '../data/cinic-10_image_classification_challenge-dataset/train/',\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed = 420,\n",
    "    image_size=(32,32),\n",
    "    batch_size=32,\n",
    "    label_mode = 'categorical'\n",
    "    )\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    '../data/cinic-10_image_classification_challenge-dataset/train/',\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed = 420,\n",
    "    image_size=(32,32),\n",
    "    batch_size=32,\n",
    "    label_mode = 'categorical'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_train_ds = train_ds.take(1).map(to_dict, num_parallel_calls=AUTOTUNE)\n",
    "dict_train_ds = dict_train_ds.map(cutmix, num_parallel_calls=AUTOTUNE)\n",
    "cutmixed_ds = dict_train_ds.map(dict_to_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in cutmixed_ds:\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i+9].numpy().astype(\"uint8\"))\n",
    "    label = \"\"\n",
    "    for j, val in enumerate(labels[i+9]):\n",
    "            if val > 0:\n",
    "                label += class_names[j] + str(np.round(val, 2)) + \" \"\n",
    "    plt.title([label])\n",
    "    plt.axis(\"off\")\n",
    "plt.savefig('../media/cutmix_example.jpg', dpi = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "import tensorflow as tf\n",
    "from keras import datasets, layers, models, losses, Model, utils\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model50 = tf.keras.applications.ResNet50(weights = 'imagenet', include_top = False, input_shape = (32,32,3))\n",
    "for layer in base_model50.layers:\n",
    "  layer.trainable = False\n",
    "inputs = layers.Input((32,32,3))\n",
    "x = RotateLayer(inputs)\n",
    "\n",
    "x = base_model50(x, training=False)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(1000, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.1))(x)\n",
    "predictions = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Create model\n",
    "head_model50 = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# Compile model\n",
    "head_model50.compile(optimizer=\"Adagrad\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train model\n",
    "history50 = head_model50.fit(train_ds, validation_data = val_ds, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet101 base model\n",
    "base_model101 = tf.keras.applications.ResNet101(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "# Freeze base model layers\n",
    "for layer in base_model101.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Pass the input through the Random Rotation layer\n",
    "inputs = layers.Input(shape=(32, 32, 3))\n",
    "x = RotateLayer(inputs)\n",
    "\n",
    "# Continue with the existing model architecture\n",
    "x = base_model101(x, training=False)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(1000, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.1))(x)\n",
    "predictions = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Create model\n",
    "head_model101 = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# Compile model\n",
    "head_model101.compile(optimizer=\"Adagrad\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train model\n",
    "history101 = head_model101.fit(train_ds, validation_data=val_ds, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model50 = tf.keras.applications.ResNet50(weights = 'imagenet', include_top = False, input_shape = (32,32,3))\n",
    "for layer in base_model50.layers:\n",
    "  layer.trainable = False\n",
    "inputs = layers.Input((32,32,3))\n",
    "x = FlipLayer(inputs)\n",
    "\n",
    "x = base_model50(x, training=False)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(1000, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.1))(x)\n",
    "predictions = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Create model\n",
    "head_model50 = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# Compile model\n",
    "head_model50.compile(optimizer=\"Adagrad\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train model\n",
    "history50 = head_model50.fit(train_ds, validation_data = val_ds, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet101 base model\n",
    "base_model101 = tf.keras.applications.ResNet101(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "# Freeze base model layers\n",
    "for layer in base_model101.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Pass the input through the Random Rotation layer\n",
    "inputs = layers.Input(shape=(32, 32, 3))\n",
    "x = FlipLayer(inputs)\n",
    "\n",
    "# Continue with the existing model architecture\n",
    "x = base_model101(x, training=False)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(1000, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.1))(x)\n",
    "predictions = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Create model\n",
    "head_model101 = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# Compile model\n",
    "head_model101.compile(optimizer=\"Adagrad\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train model\n",
    "history101 = head_model101.fit(train_ds, validation_data=val_ds, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decolorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model50 = tf.keras.applications.ResNet50(weights = 'imagenet', include_top = False, input_shape = (32,32,3))\n",
    "for layer in base_model50.layers:\n",
    "  layer.trainable = False\n",
    "inputs = layers.Input((32,32,3))\n",
    "x = DecolorLayer(inputs)\n",
    "\n",
    "x = base_model50(x, training=False)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(1000, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.1))(x)\n",
    "predictions = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Create model\n",
    "head_model50 = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# Compile model\n",
    "head_model50.compile(optimizer=\"Adagrad\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train model\n",
    "history50 = head_model50.fit(train_ds, validation_data = val_ds, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet101 base model\n",
    "base_model101 = tf.keras.applications.ResNet101(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "# Freeze base model layers\n",
    "for layer in base_model101.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Pass the input through the Random Rotation layer\n",
    "inputs = layers.Input(shape=(32, 32, 3))\n",
    "x = DecolorLayer(inputs)\n",
    "\n",
    "# Continue with the existing model architecture\n",
    "x = base_model101(x, training=False)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(1000, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.1))(x)\n",
    "predictions = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Create model\n",
    "head_model101 = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# Compile model\n",
    "head_model101.compile(optimizer=\"Adagrad\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train model\n",
    "history101 = head_model101.fit(train_ds, validation_data=val_ds, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model50 = tf.keras.applications.ResNet50(weights = 'imagenet', include_top = False, input_shape = (32,32,3))\n",
    "for layer in base_model50.layers:\n",
    "  layer.trainable = False\n",
    "inputs = layers.Input((32,32,3))\n",
    "inputs = RescaleLayer(inputs)\n",
    "x = GaussianNoise(inputs)\n",
    "\n",
    "x = base_model50(x, training=False)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(1000, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.1))(x)\n",
    "predictions = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Create model\n",
    "head_model50 = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# Compile model\n",
    "head_model50.compile(optimizer=\"Adagrad\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train model\n",
    "history50 = head_model50.fit(train_ds, validation_data = val_ds, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet101 base model\n",
    "base_model101 = tf.keras.applications.ResNet101(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "# Freeze base model layers\n",
    "for layer in base_model101.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Pass the input through the Random Rotation layer\n",
    "inputs = layers.Input(shape=(32, 32, 3))\n",
    "inputs = RescaleLayer(inputs)\n",
    "x = GaussianNoise(inputs)\n",
    "\n",
    "# Continue with the existing model architecture\n",
    "x = base_model101(x, training=False)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(1000, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.1))(x)\n",
    "predictions = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Create model\n",
    "head_model101 = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# Compile model\n",
    "head_model101.compile(optimizer=\"Adagrad\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train model\n",
    "history101 = head_model101.fit(train_ds, validation_data=val_ds, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUTMIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model50 = tf.keras.applications.ResNet50(weights = 'imagenet', include_top = False, input_shape = (32,32,3))\n",
    "for layer in base_model50.layers:\n",
    "  layer.trainable = False\n",
    "  \n",
    "input_images = layers.Input((32, 32, 3), name = 'images')\n",
    "input_images = layers.Rescaling(1./255)(input_images)\n",
    "input_labels = layers.Input((10,), name = 'labels')\n",
    "# Apply CutMix to images here\n",
    "inputs = keras_cv.layers.CutMix()({'images' : input_images, 'labels' : input_labels})['images']\n",
    "x = base_model50(inputs, training=False)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(1000, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.1))(x)\n",
    "predictions = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Create model\n",
    "head_model50 = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# Compile model\n",
    "head_model50.compile(optimizer=\"Adagrad\", loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.1), metrics=[\"accuracy\"])\n",
    "\n",
    "# Train model\n",
    "history50 = head_model50.fit(train_ds, validation_data = val_ds, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet101 base model\n",
    "base_model101 = tf.keras.applications.ResNet101(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "# Freeze base model layers\n",
    "for layer in base_model101.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Pass the input through the Random Rotation layer\n",
    "input_images = layers.Input((32, 32, 3), name = 'images')\n",
    "input_labels = layers.Input((10,), name = 'labels')\n",
    "# Apply CutMix to images here\n",
    "inputs = keras_cv.layers.CutMix()({'images' : input_images, 'labels' : input_labels})['images']\n",
    "\n",
    "# Continue with the existing model architecture\n",
    "x = base_model101(inputs, training=False)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(1000, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.1))(x)\n",
    "predictions = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Create model\n",
    "head_model101 = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# Compile model\n",
    "head_model101.compile(optimizer=\"Adagrad\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train model\n",
    "history101 = head_model101.fit(train_ds, validation_data=val_ds, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combined augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = keras_cv.layers.RandomAugmentationPipeline(\n",
    "    layers=[keras_cv.layers.Grayscale(output_channels=3),\n",
    "            layers.RandomRotation(0.2),\n",
    "            layers.RandomFlip(\"horizontal\"),\n",
    "            layers.GaussianNoise(stddev = 0.1)\n",
    "            ],\n",
    "    augmentations_per_image=2,\n",
    ")\n",
    "\n",
    "def apply_pipeline(images):\n",
    "    images = pipeline(images)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model50 = tf.keras.applications.ResNet50(weights = 'imagenet', include_top = False, input_shape = (32,32,3))\n",
    "for layer in base_model50.layers:\n",
    "  layer.trainable = False\n",
    "  \n",
    "input_images = layers.Input((32, 32, 3), name = 'images')\n",
    "input_labels = layers.Input((10,), name = 'labels')\n",
    "# Apply CutMix to images here\n",
    "inputs = keras_cv.layers.CutMix()({'images' : input_images, 'labels' : input_labels})['images']\n",
    "inputs = layers.Lambda(apply_pipeline, output_shape=(32, 32, 3))(inputs) # rest of the augmentations here\n",
    "x = base_model50(inputs, training=False)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(1000, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.1))(x)\n",
    "predictions = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Create model\n",
    "head_model50 = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# Compile model\n",
    "head_model50.compile(optimizer=\"Adagrad\", loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.1), metrics=[\"accuracy\"])\n",
    "\n",
    "# Train model\n",
    "history50 = head_model50.fit(train_ds, validation_data = val_ds, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet101 base model\n",
    "base_model101 = tf.keras.applications.ResNet101(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "# Freeze base model layers\n",
    "for layer in base_model101.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "input_images = layers.Input((32, 32, 3), name = 'images')\n",
    "input_labels = layers.Input((10,), name = 'labels')\n",
    "# Apply CutMix to images here\n",
    "inputs = keras_cv.layers.CutMix()({'images' : input_images, 'labels' : input_labels})['images']\n",
    "inputs = layers.Lambda(apply_pipeline, output_shape=(32, 32, 3))(inputs) # rest of the augmentations here\n",
    "\n",
    "\n",
    "x = base_model101(inputs, training=False)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(1000, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.1))(x)\n",
    "predictions = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Create model\n",
    "head_model101 = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# Compile model\n",
    "head_model101.compile(optimizer=\"Adagrad\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train model\n",
    "history101 = head_model101.fit(train_ds, validation_data=val_ds, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# long training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = keras_cv.layers.RandomAugmentationPipeline(\n",
    "    layers=[keras_cv.layers.Grayscale(output_channels=3),\n",
    "            layers.RandomRotation(0.2),\n",
    "            layers.RandomFlip(\"horizontal\"),\n",
    "            layers.GaussianNoise(stddev = 0.05)\n",
    "            ],\n",
    "    augmentations_per_image=2,\n",
    ")\n",
    "\n",
    "def apply_pipeline(images):\n",
    "    images = pipeline(images)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model50 = tf.keras.applications.ResNet50(weights = 'imagenet', include_top = False, input_shape = (32,32,3))\n",
    "for layer in base_model50.layers:\n",
    "  layer.trainable = True\n",
    "  \n",
    "input_images = layers.Input((32, 32, 3), name = 'images')\n",
    "input_labels = layers.Input((10,), name = 'labels')\n",
    "# Apply CutMix to images here\n",
    "inputs = keras_cv.layers.CutMix()({'images' : input_images, 'labels' : input_labels})['images']\n",
    "inputs = layers.Lambda(apply_pipeline, output_shape=(32, 32, 3))(inputs) # rest of the augmentations here\n",
    "x = base_model50(inputs, training=False)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(1000, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.05))(x)\n",
    "predictions = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Create model\n",
    "head_model50 = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# Compile model\n",
    "head_model50.compile(optimizer=\"Adagrad\", loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.1), metrics=[\"accuracy\"])\n",
    "\n",
    "# Train model\n",
    "history50 = head_model50.fit(train_ds, validation_data = val_ds, epochs=25)\n",
    "head_model50.save_weights(\"head_model50_trained_whole.weights.h5\")\n",
    "base_model50.save_weights(\"base_model50_trained_whole.weights.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
